{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()\n",
    "tf.add(1, 2).numpy()\n",
    "3\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "hello.numpy()\n",
    "'Hello, TensorFlow!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /workspace && ls -lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /workspace/nvidia-examples/ && ls -lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cd /workspace/nvidia-examples/cnn/ && ls -lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /workspace/nvidia-examples/cnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat ./alexnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./alexnet.py 2>/tmp/errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./alexnet.py --data_dir /datasets/imagenet_TFrecords 2>/tmp/errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./inception_v3.py --data_dir /datasets/imagenet_TFrecords 2>/tmp/errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./resnet.py --layers=50 2>/tmp/errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!./resnet.py --layers=50 --data_dir=\"/datasets/imagenet_TFrecords\" --precision=fp16 --log_dir=\"/output/resnet50\" 2>/tmp/error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpiexec --allow-run-as-root --bind-to socket -np 4 python /workspace/nvidia-examples/resnet.py --layers=50 --data_dir=/datasets/imagenet_TFrecords --precision=fp16 --log_dir=/output/resnet50 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic data\n",
    "mpiexec --allow-run-as-root --bind-to socket -np 4 python resnet.py --layers=50 --precision=fp16 --log_dir=/output\n",
    "\n",
    "(Alexnet)\n",
    "./alexnet.py --data_dir /datasets/imagenet_TFrecords\n",
    "\n",
    "(Alexnet w/DALI)\n",
    "./alexnet.py --data_dir /datasets/imagenet_TFrecords --data_idx_dir /datasets/imagenet_idx --use_dali GPU\n",
    "\n",
    "(Inception V3 w/DALI)\n",
    "./inception_v3.py --data_dir /datasets/imagenet_TFrecords --data_idx_dir /datasets/imagenet_idx --use_dali GPU\n",
    "\n",
    "To prep for DALI:\n",
    "mkdir /imagenet_idx\n",
    "for x in `ls /datasets/imagenet_TFrecords`; do tfrecord2idx /datasets/imagenet_TFrecords/$x /imagenet_idx/$x.idx; done\n",
    "\n",
    "https://github.com/NVIDIA/DeepLearningExamples/tree/master/TensorFlow/Classification/imagenet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "OpenSeq Examples:\n",
    "Training run (long):\n",
    "cd nvidia-examples/OpenSeq2Seq\n",
    "mkdir data\n",
    "ln -s /datasets/imagenet_TFrecords data/tf-imagenet\n",
    "( rm -rf tmp_log_folder )\n",
    "python run.py --config_file example_configs/image2label/resnet-50-v2.py --continue_learning\n",
    "\n",
    "Speech Example from https://nvidia.github.io/OpenSeq2Seq/html/installation.html#how-to-download-a-language-model-for-a-ctc-decoder-optional (good to “watch” a quick training - ~ 2 minutes):\n",
    "cd nvidia-examples/OpenSeq2Seq\n",
    "( rm -rf tmp_log_folder )\n",
    "python run.py --config_file=example_configs/speech2text/ds2_toy_config.py --mode=train_eval\n",
    "\n",
    "Non-toy speech example (way too long to show):\n",
    "cd nvidia-examples/OpenSeq2Seq\n",
    "ln -s /datasets/openseq/librispeech data\n",
    "( rm -rf tmp_log_folder )\n",
    "python run.py --config_file=example_configs/speech2text/ds2_medium_4gpus.py --mode=train_eval\n",
    "\n",
    "\n",
    "Big_lstm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Temp ScottE\n",
    "mpiexec --allow-run-as-root --bind-to socket -np 8 ./resnet.py --layers=50 --data_dir=/datasets/imagenet_TFrecords --precision=fp16 --data_idx_dir /imagenet_idx --use_dali GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m tensorflow.models.image.mnist.convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float32_variable_storage_getter(getter, name, shape=None, dtype=None,\n",
    "                                    initializer=None, regularizer=None,\n",
    "                                    trainable=True,\n",
    "                                    *args, **kwargs):\n",
    "    \"\"\"Custom variable getter that forces trainable variables to be stored in\n",
    "    float32 precision and then casts them to the training precision.\n",
    "    \"\"\"\n",
    "    storage_dtype = tf.float32 if trainable else dtype\n",
    "    variable = getter(name, shape, dtype=storage_dtype,\n",
    "                      initializer=initializer, regularizer=regularizer,\n",
    "                      trainable=trainable,\n",
    "                      *args, **kwargs)\n",
    "    if trainable and dtype != tf.float32:\n",
    "        variable = tf.cast(variable, dtype)\n",
    "    return variable\n",
    "\n",
    "def gradients_with_loss_scaling(loss, variables, loss_scale):\n",
    "    \"\"\"Gradient calculation with loss scaling to improve numerical stability\n",
    "    when training with float16.\n",
    "    \"\"\"\n",
    "    return [grad / loss_scale\n",
    "            for grad in tf.gradients(loss * loss_scale, variables)]\n",
    "\n",
    "def create_simple_model(nbatch, nin, nout, dtype):\n",
    "    \"\"\"A simple softmax model.\"\"\"\n",
    "    data    = tf.placeholder(dtype, shape=(nbatch, nin))\n",
    "    weights = tf.get_variable('weights', (nin, nout), dtype)\n",
    "    biases  = tf.get_variable('biases',        nout,  dtype,\n",
    "                              initializer=tf.zeros_initializer())\n",
    "    logits  = tf.matmul(data, weights) + biases\n",
    "    target  = tf.placeholder(tf.float32, shape=(nbatch, nout))\n",
    "    # Note: The softmax should be computed in float32 precision\n",
    "    loss    = tf.losses.softmax_cross_entropy(\n",
    "        target, tf.cast(logits, tf.float32))\n",
    "    return data, target, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    nbatch = 64\n",
    "    nin    = 104\n",
    "    nout   = 16\n",
    "    learning_rate = 0.1\n",
    "    momentum      = 0.9\n",
    "    loss_scale    = 128\n",
    "    dtype         = tf.float16\n",
    "    tf.set_random_seed(1234)\n",
    "    np.random.seed(4321)\n",
    "\n",
    "    # Create training graph\n",
    "    with tf.device('/gpu:0'), \\\n",
    "         tf.variable_scope(\n",
    "             # Note: This forces trainable variables to be stored as float32\n",
    "             'fp32_storage', custom_getter=float32_variable_storage_getter):\n",
    "        data, target, loss = create_simple_model(nbatch, nin, nout, dtype)\n",
    "        variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        # Note: Loss scaling can improve numerical stability for fp16 training\n",
    "        grads = gradients_with_loss_scaling(loss, variables, loss_scale)\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "        training_step_op = optimizer.apply_gradients(zip(grads, variables))\n",
    "        init_op = tf.global_variables_initializer()\n",
    "\n",
    "    # Run training\n",
    "    sess = tf.Session()\n",
    "    sess.run(init_op)\n",
    "    np_data   = np.random.normal(size=(nbatch, nin)).astype(np.float16)\n",
    "    np_target = np.zeros((nbatch, nout), dtype=np.float32)\n",
    "    np_target[:,0] = 1\n",
    "    print 'Step Loss'\n",
    "    for step in xrange(30):\n",
    "        np_loss, _ = sess.run([loss, training_step_op],\n",
    "                              feed_dict={data: np_data, target: np_target})\n",
    "        print '%4i %6f' % (step + 1, np_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
