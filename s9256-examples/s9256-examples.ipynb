{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.enable_eager_execution()\n",
    "tf.add(1, 2).numpy()\n",
    "3\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "hello.numpy()\n",
    "'Hello, TensorFlow!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /workspace && ls -lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /workspace/nvidia-examples/ && ls -lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cd /workspace/nvidia-examples/cnn/ && ls -lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tensorflow/nvidia-examples/cnn\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/nvidia-examples/cnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python\r\n",
      "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\r\n",
      "#\r\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
      "# you may not use this file except in compliance with the License.\r\n",
      "# You may obtain a copy of the License at\r\n",
      "#\r\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\r\n",
      "#\r\n",
      "# Unless required by applicable law or agreed to in writing, software\r\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
      "# See the License for the specific language governing permissions and\r\n",
      "# limitations under the License.\r\n",
      "# ==============================================================================\r\n",
      "\r\n",
      "from __future__ import print_function\r\n",
      "from builtins import range\r\n",
      "import nvutils\r\n",
      "import tensorflow as tf\r\n",
      "\r\n",
      "nvutils.init()\r\n",
      "\r\n",
      "default_args = {\r\n",
      "    'image_width' : 227,\r\n",
      "    'image_height' : 227,\r\n",
      "    'image_format' : 'channels_first',\r\n",
      "    'distort_color' : False,\r\n",
      "    'batch_size' : 256,\r\n",
      "    'data_dir' : None,\r\n",
      "    'log_dir' : None,\r\n",
      "    'export_dir' : None,\r\n",
      "    'precision' : 'fp16',\r\n",
      "    'momentum' : 0.9,\r\n",
      "    'learning_rate_init' : 1.0,\r\n",
      "    'learning_rate_power' : 2.0,\r\n",
      "    'weight_decay' : 5e-4,\r\n",
      "    'loss_scale' : 128.0,\r\n",
      "    'larc_eta' : 0.0023,\r\n",
      "    'larc_mode' : 'clip',\r\n",
      "    'num_iter' : 91,\r\n",
      "    'checkpoint_secs' : None,\r\n",
      "    'display_every' : 10,\r\n",
      "    'iter_unit' : 'epoch'\r\n",
      "}\r\n",
      "\r\n",
      "args, _ = nvutils.parse_cmdline(default_args)\r\n",
      "\r\n",
      "def alexnet_owt(inputs, training):\r\n",
      "    \"\"\"Alexnet One Weird Trick model\r\n",
      "    https://arxiv.org/abs/1404.5997\r\n",
      "    \"\"\"\r\n",
      "    builder = nvutils.LayerBuilder(tf.nn.relu, args['image_format'], training)\r\n",
      "    # Note: VALID requires padding the images by 3 in width and height\r\n",
      "    x = inputs\r\n",
      "    x = builder.conv2d(x, 64, 11, 4, 'VALID')\r\n",
      "    x = builder.max_pooling2d(x, 3, 2)\r\n",
      "    x = builder.conv2d(x, 192,   5, 1, 'SAME')\r\n",
      "    x = builder.max_pooling2d(x, 3, 2)\r\n",
      "    x = builder.conv2d(x, 384,   3, 1, 'SAME')\r\n",
      "    x = builder.conv2d(x, 256,   3, 1, 'SAME')\r\n",
      "    x = builder.conv2d(x, 256,   3, 1, 'SAME')\r\n",
      "    x = builder.max_pooling2d(x, 3, 2)\r\n",
      "    x = builder.flatten2d(x)\r\n",
      "    x = builder.dense(x, 4096)\r\n",
      "    x = builder.dropout(x)\r\n",
      "    x = builder.dense(x, 4096)\r\n",
      "    x = builder.dropout(x)\r\n",
      "    return x\r\n",
      "\r\n",
      "if args['predict']:\r\n",
      "    if args['log_dir'] is not None and args['data_dir'] is not None:\r\n",
      "        nvutils.predict(alexnet_owt, args)\r\n",
      "else:\r\n",
      "    nvutils.train(alexnet_owt, args)\r\n",
      "    if args['log_dir'] is not None and args['data_dir'] is not None:\r\n",
      "        nvutils.validate(alexnet_owt, args)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./alexnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "Script arguments:\n",
      "  --display_every 10\n",
      "  --num_iter 91\n",
      "  --precision fp16\n",
      "  --batch_size 256\n",
      "  --predict False\n",
      "  --iter_unit epoch\n",
      "Training\n",
      "  Step Epoch Img/sec   Loss  LR\n",
      "     1   1.0    76.7  6.922  9.996 1.00000\n",
      "    10  10.0   844.0  5.879  8.943 0.81198\n",
      "    20  20.0  6629.0  5.683  8.728 0.62601\n",
      "    30  30.0  6630.8  5.605  8.619 0.46420\n",
      "    40  40.0  6665.7  5.585  8.559 0.32653\n",
      "    50  50.0  6638.2  5.553  8.489 0.21302\n",
      "    60  60.0  6643.6  5.529  8.434 0.12366\n",
      "    70  70.0  6645.9  5.492  8.378 0.05845\n",
      "    80  80.0  6628.7  5.475  8.351 0.01739\n",
      "    90  90.0  6641.2  5.427  8.302 0.00048\n"
     ]
    }
   ],
   "source": [
    "!./alexnet.py 2>/tmp/errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "Script arguments:\n",
      "  --num_iter 91\n",
      "  --batch_size 256\n",
      "  --predict False\n",
      "  --precision fp16\n",
      "  --data_dir /datasets/imagenet_TFrecords\n",
      "  --display_every 10\n",
      "  --iter_unit epoch\n",
      "Training\n",
      "  Step Epoch Img/sec   Loss  LR\n",
      "     1   0.0    80.1  6.919  9.993 1.00000\n",
      "    10   0.0   778.1  6.911  9.951 0.99996\n",
      "    20   0.0  4273.9  6.916  9.836 0.99992\n",
      "    30   0.0  4476.0  6.909  9.620 0.99987\n",
      "    40   0.0  3934.0  6.902  9.379 0.99983\n",
      "    50   0.0  4118.3  6.909  9.157 0.99978\n",
      "    60   0.0  4210.7  6.909  8.941 0.99974\n",
      "    70   0.0  4482.8  6.905  8.740 0.99970\n",
      "    80   0.0  4387.3  6.913  8.568 0.99965\n",
      "    90   0.0  4489.4  6.905  8.397 0.99961\n",
      "   100   0.0  4508.3  6.911  8.255 0.99957\n",
      "   110   0.0  4204.9  6.910  8.122 0.99952\n",
      "   120   0.0  4523.4  6.911  8.003 0.99948\n",
      "   130   0.0  4543.2  6.909  7.893 0.99943\n",
      "   140   0.0  4480.6  6.911  7.798 0.99939\n",
      "   150   0.0  4088.5  6.908  7.707 0.99935\n",
      "   160   0.0  4004.3  6.903  7.625 0.99930\n",
      "   170   0.0  4175.2  6.901  7.556 0.99926\n",
      "   180   0.0  4549.0  6.909  7.504 0.99921\n",
      "   190   0.0  4565.4  6.897  7.440 0.99917\n",
      "   200   0.0  4477.4  6.854  7.353 0.99913\n",
      "   210   0.0  4427.5  6.854  7.317 0.99908\n",
      "   220   0.0  4501.1  6.862  7.293 0.99904\n",
      "   230   0.0  4149.0  6.871  7.280 0.99899\n",
      "   240   0.0  4312.3  6.867  7.261 0.99895\n",
      "   250   0.0  4025.8  6.868  7.248 0.99891\n",
      "   260   0.1  4066.7  6.868  7.236 0.99886\n",
      "   270   0.1  3949.6  6.862  7.217 0.99882\n",
      "   280   0.1  4235.4  6.857  7.201 0.99878\n",
      "   290   0.1  4146.5  6.873  7.206 0.99873\n",
      "   300   0.1  4373.0  6.844  7.167 0.99869\n",
      "   310   0.1  4165.7  6.845  7.159 0.99864\n",
      "   320   0.1  4003.3  6.825  7.131 0.99860\n",
      "   330   0.1  4176.8  6.841  7.140 0.99856\n",
      "   340   0.1  4296.7  6.807  7.099 0.99851\n",
      "   350   0.1  4447.2  6.818  7.105 0.99847\n",
      "   360   0.1  4213.1  6.874  7.155 0.99842\n",
      "   370   0.1  4586.3  6.799  7.074 0.99838\n",
      "   380   0.1  4617.7  6.796  7.065 0.99834\n",
      "   390   0.1  4692.0  6.847  7.110 0.99829\n",
      "   400   0.1  4406.6  6.797  7.055 0.99825\n",
      "   410   0.1  4509.1  6.804  7.056 0.99820\n",
      "   420   0.1  4609.3  6.809  7.057 0.99816\n",
      "   430   0.1  4594.5  6.823  7.066 0.99812\n",
      "   440   0.1  4302.6  6.840  7.078 0.99807\n",
      "   450   0.1  4503.0  6.829  7.064 0.99803\n",
      "   460   0.1  4548.5  6.785  7.015 0.99799\n",
      "   470   0.1  4486.6  6.841  7.067 0.99794\n",
      "   480   0.1  4143.6  6.808  7.030 0.99790\n",
      "   490   0.1  4270.9  6.788  7.007 0.99785\n",
      "   500   0.1  4214.4  6.764  6.980 0.99781\n",
      "   510   0.1  4216.1  6.769  6.982 0.99777\n",
      "   520   0.1  3998.9  6.792  7.002 0.99772\n",
      "   530   0.1  4032.5  6.738  6.945 0.99768\n",
      "   540   0.1  4213.1  6.778  6.982 0.99763\n",
      "   550   0.1  4546.6  6.796  6.998 0.99759\n",
      "   560   0.1  4445.9  6.797  6.996 0.99755\n",
      "   570   0.1  4215.5  6.746  6.943 0.99750\n",
      "   580   0.1  4424.4  6.783  6.977 0.99746\n",
      "   590   0.1  4575.4  6.814  7.006 0.99741\n",
      "   600   0.1  4082.5  6.817  7.006 0.99737\n",
      "   610   0.1  3935.8  6.829  7.016 0.99733\n",
      "   620   0.1  4144.4  6.761  6.946 0.99728\n",
      "   630   0.1  4574.8  6.764  6.947 0.99724\n",
      "   640   0.1  4339.8  6.819  6.999 0.99720\n",
      "   650   0.1  4158.7  6.780  6.958 0.99715\n",
      "   660   0.1  4023.6  6.748  6.924 0.99711\n",
      "   670   0.1  4431.2  6.780  6.954 0.99706\n",
      "   680   0.1  4218.4  6.693  6.865 0.99702\n",
      "   690   0.1  4397.7  6.731  6.901 0.99698\n",
      "   700   0.1  4391.4  6.756  6.925 0.99693\n",
      "   710   0.1  4180.9  6.793  6.960 0.99689\n",
      "   720   0.1  4484.4  6.838  7.003 0.99684\n",
      "   730   0.1  4497.0  6.791  6.955 0.99680\n",
      "   740   0.1  4567.7  6.758  6.920 0.99676\n",
      "   750   0.1  4027.0  6.759  6.920 0.99671\n",
      "   760   0.2  3994.6  6.787  6.946 0.99667\n",
      "   770   0.2  4143.8  6.846  7.004 0.99663\n",
      "   780   0.2  4265.9  6.779  6.936 0.99658\n",
      "   790   0.2  4212.7  6.758  6.914 0.99654\n",
      "   800   0.2  4060.9  6.783  6.938 0.99649\n",
      "   810   0.2  4253.8  6.845  6.998 0.99645\n",
      "   820   0.2  4113.8  6.803  6.955 0.99641\n",
      "   830   0.2  4152.3  6.734  6.885 0.99636\n",
      "   840   0.2  4796.9  6.733  6.883 0.99632\n",
      "   850   0.2  4771.3  6.769  6.918 0.99627\n",
      "   860   0.2  4827.5  6.758  6.906 0.99623\n",
      "   870   0.2  4765.6  6.767  6.913 0.99619\n",
      "   880   0.2  4672.0  6.725  6.870 0.99614\n",
      "   890   0.2  4725.8  6.681  6.826 0.99610\n",
      "   900   0.2  4743.0  6.742  6.885 0.99606\n",
      "   910   0.2  4690.2  6.772  6.915 0.99601\n",
      "   920   0.2  4701.9  6.711  6.853 0.99597\n",
      "   930   0.2  4590.3  6.693  6.835 0.99592\n",
      "   940   0.2  4200.6  6.771  6.912 0.99588\n",
      "   950   0.2  4220.9  6.737  6.877 0.99584\n",
      "   960   0.2  4643.1  6.716  6.855 0.99579\n",
      "   970   0.2  4671.5  6.732  6.870 0.99575\n",
      "   980   0.2  4735.3  6.706  6.843 0.99570\n",
      "   990   0.2  4365.8  6.719  6.856 0.99566\n",
      "  1000   0.2  4122.6  6.813  6.949 0.99562\n",
      "  1010   0.2  4206.6  6.708  6.843 0.99557\n",
      "  1020   0.2  4345.0  6.679  6.814 0.99553\n",
      "  1030   0.2  4417.6  6.733  6.867 0.99549\n",
      "  1040   0.2  4143.6  6.728  6.862 0.99544\n",
      "  1050   0.2  4005.6  6.716  6.849 0.99540\n",
      "  1060   0.2  4155.8  6.744  6.876 0.99535\n",
      "  1070   0.2  4088.6  6.703  6.835 0.99531\n",
      "  1080   0.2  4305.0  6.693  6.823 0.99527\n",
      "  1090   0.2  4284.9  6.742  6.872 0.99522\n",
      "  1100   0.2  4412.0  6.705  6.834 0.99518\n",
      "  1110   0.2  4138.4  6.673  6.802 0.99514\n",
      "  1120   0.2  4125.5  6.793  6.921 0.99509\n",
      "  1130   0.2  4030.6  6.687  6.815 0.99505\n",
      "  1140   0.2  3960.7  6.730  6.857 0.99500\n",
      "  1150   0.2  4005.5  6.752  6.879 0.99496\n",
      "  1160   0.2  4041.6  6.711  6.837 0.99492\n",
      "  1170   0.2  4118.2  6.749  6.875 0.99487\n",
      "  1180   0.2  4067.8  6.692  6.816 0.99483\n",
      "  1190   0.2  4181.3  6.680  6.804 0.99478\n",
      "  1200   0.2  4220.5  6.710  6.834 0.99474\n",
      "  1210   0.2  4074.9  6.636  6.759 0.99470\n",
      "  1220   0.2  4052.2  6.736  6.859 0.99465\n",
      "  1230   0.2  4020.0  6.732  6.855 0.99461\n",
      "  1240   0.2  4013.1  6.674  6.796 0.99457\n",
      "  1250   0.2  3980.4  6.703  6.825 0.99452\n",
      "  1260   0.3  4148.0  6.720  6.841 0.99448\n",
      "  1270   0.3  4192.1  6.763  6.884 0.99443\n",
      "  1280   0.3  4092.7  6.655  6.776 0.99439\n",
      "  1290   0.3  4165.7  6.634  6.755 0.99435\n",
      "  1300   0.3  4137.8  6.701  6.821 0.99430\n",
      "  1310   0.3  4580.3  6.699  6.819 0.99426\n",
      "  1320   0.3  4221.4  6.684  6.803 0.99422\n",
      "  1330   0.3  4166.8  6.661  6.780 0.99417\n",
      "  1340   0.3  4558.1  6.607  6.726 0.99413\n",
      "  1350   0.3  4245.4  6.728  6.847 0.99408\n",
      "  1360   0.3  4413.4  6.671  6.790 0.99404\n",
      "  1370   0.3  4459.4  6.733  6.852 0.99400\n",
      "  1380   0.3  4311.0  6.640  6.758 0.99395\n",
      "  1390   0.3  4559.5  6.645  6.763 0.99391\n",
      "  1400   0.3  4490.3  6.596  6.713 0.99386\n",
      "  1410   0.3  4233.4  6.683  6.800 0.99382\n",
      "  1420   0.3  4070.0  6.584  6.702 0.99378\n",
      "  1430   0.3  4098.5  6.658  6.776 0.99373\n",
      "  1440   0.3  4435.3  6.682  6.799 0.99369\n",
      "  1450   0.3  4244.3  6.611  6.728 0.99365\n",
      "  1460   0.3  4300.0  6.690  6.807 0.99360\n",
      "  1470   0.3  4462.5  6.597  6.714 0.99356\n",
      "  1480   0.3  4215.6  6.655  6.771 0.99351\n",
      "  1490   0.3  4560.8  6.633  6.750 0.99347\n",
      "  1500   0.3  4578.8  6.696  6.812 0.99343\n",
      "  1510   0.3  4120.7  6.563  6.679 0.99338\n",
      "  1520   0.3  4506.8  6.670  6.786 0.99334\n",
      "  1530   0.3  4502.5  6.592  6.708 0.99330\n",
      "  1540   0.3  4665.7  6.664  6.780 0.99325\n",
      "  1550   0.3  4282.7  6.636  6.751 0.99321\n",
      "  1560   0.3  4524.0  6.546  6.662 0.99316\n",
      "  1570   0.3  4577.2  6.638  6.753 0.99312\n",
      "  1580   0.3  4639.3  6.540  6.655 0.99308\n",
      "  1590   0.3  4606.0  6.533  6.648 0.99303\n",
      "  1600   0.3  4527.8  6.573  6.688 0.99299\n",
      "  1610   0.3  4334.4  6.617  6.732 0.99295\n",
      "  1620   0.3  4461.6  6.680  6.795 0.99290\n",
      "  1630   0.3  4030.1  6.594  6.709 0.99286\n",
      "  1640   0.3  4033.4  6.549  6.664 0.99281\n",
      "  1650   0.3  4088.1  6.538  6.652 0.99277\n",
      "  1660   0.3  4073.9  6.527  6.642 0.99273\n",
      "  1670   0.3  4059.7  6.647  6.761 0.99268\n",
      "  1680   0.3  4037.4  6.573  6.687 0.99264\n",
      "  1690   0.3  4032.3  6.550  6.665 0.99260\n",
      "  1700   0.3  4050.1  6.498  6.613 0.99255\n",
      "  1710   0.3  4002.3  6.524  6.638 0.99251\n",
      "  1720   0.3  4525.0  6.636  6.751 0.99246\n",
      "  1730   0.3  4320.1  6.511  6.625 0.99242\n",
      "  1740   0.3  4437.1  6.579  6.693 0.99238\n",
      "  1750   0.3  4496.4  6.562  6.676 0.99233\n",
      "  1760   0.4  4541.9  6.538  6.652 0.99229\n",
      "  1770   0.4  4373.3  6.516  6.630 0.99225\n",
      "  1780   0.4  4135.5  6.560  6.674 0.99220\n",
      "  1790   0.4  4069.1  6.590  6.704 0.99216\n",
      "  1800   0.4  4076.0  6.505  6.619 0.99211\n",
      "  1810   0.4  4230.0  6.542  6.656 0.99207\n",
      "  1820   0.4  4295.3  6.651  6.764 0.99203\n",
      "  1830   0.4  4097.2  6.480  6.593 0.99198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1840   0.4  4542.2  6.519  6.632 0.99194\n",
      "  1850   0.4  4636.6  6.595  6.708 0.99190\n",
      "  1860   0.4  4724.7  6.555  6.668 0.99185\n",
      "  1870   0.4  4350.0  6.627  6.741 0.99181\n",
      "  1880   0.4  4096.4  6.591  6.705 0.99176\n",
      "  1890   0.4  4373.1  6.649  6.763 0.99172\n",
      "  1900   0.4  4037.1  6.609  6.722 0.99168\n",
      "  1910   0.4  4033.8  6.511  6.624 0.99163\n",
      "  1920   0.4  4035.8  6.579  6.693 0.99159\n",
      "  1930   0.4  4232.3  6.453  6.567 0.99155\n",
      "  1940   0.4  4641.9  6.529  6.643 0.99150\n",
      "  1950   0.4  4549.8  6.525  6.638 0.99146\n",
      "  1960   0.4  4121.4  6.457  6.571 0.99141\n",
      "  1970   0.4  4134.7  6.540  6.653 0.99137\n",
      "  1980   0.4  4533.2  6.519  6.633 0.99133\n",
      "  1990   0.4  4599.4  6.548  6.661 0.99128\n",
      "  2000   0.4  4641.4  6.312  6.426 0.99124\n",
      "  2010   0.4  4395.7  6.521  6.635 0.99120\n",
      "  2020   0.4  4376.6  6.473  6.587 0.99115\n",
      "  2030   0.4  4538.2  6.547  6.661 0.99111\n",
      "  2040   0.4  4504.6  6.479  6.592 0.99106\n",
      "  2050   0.4  4123.7  6.435  6.549 0.99102\n",
      "  2060   0.4  4041.6  6.513  6.627 0.99098\n",
      "  2070   0.4  4517.3  6.486  6.600 0.99093\n",
      "  2080   0.4  4432.6  6.502  6.616 0.99089\n",
      "  2090   0.4  4602.6  6.440  6.553 0.99085\n",
      "  2100   0.4  4301.5  6.394  6.508 0.99080\n",
      "  2110   0.4  4247.0  6.397  6.511 0.99076\n",
      "  2120   0.4  4059.1  6.370  6.484 0.99071\n",
      "  2130   0.4  4429.9  6.447  6.561 0.99067\n",
      "  2140   0.4  4553.5  6.491  6.605 0.99063\n",
      "  2150   0.4  4395.2  6.368  6.482 0.99058\n",
      "  2160   0.4  4614.0  6.488  6.602 0.99054\n",
      "  2170   0.4  4563.5  6.476  6.590 0.99050\n",
      "  2180   0.4  4781.0  6.483  6.597 0.99045\n",
      "  2190   0.4  4809.6  6.438  6.552 0.99041\n",
      "  2200   0.4  4700.4  6.519  6.633 0.99037\n",
      "  2210   0.4  4304.9  6.405  6.519 0.99032\n",
      "  2220   0.4  4155.6  6.362  6.476 0.99028\n",
      "  2230   0.4  4505.4  6.485  6.600 0.99023\n",
      "  2240   0.4  4652.0  6.540  6.654 0.99019\n",
      "  2250   0.4  4594.0  6.429  6.544 0.99015\n",
      "  2260   0.5  4784.2  6.565  6.679 0.99010\n",
      "  2270   0.5  4833.0  6.433  6.548 0.99006\n",
      "  2280   0.5  4829.9  6.476  6.591 0.99002\n",
      "  2290   0.5  4711.7  6.429  6.544 0.98997\n",
      "  2300   0.5  4766.5  6.452  6.567 0.98993\n",
      "  2310   0.5  4681.1  6.426  6.541 0.98988\n",
      "  2320   0.5  4721.5  6.347  6.463 0.98984\n",
      "  2330   0.5  4784.8  6.468  6.584 0.98980\n",
      "  2340   0.5  4840.7  6.377  6.493 0.98975\n",
      "  2350   0.5  4606.5  6.367  6.483 0.98971\n",
      "  2360   0.5  4586.8  6.385  6.501 0.98967\n",
      "  2370   0.5  4341.5  6.343  6.459 0.98962\n",
      "  2380   0.5  4169.5  6.381  6.496 0.98958\n",
      "  2390   0.5  4368.6  6.451  6.567 0.98953\n",
      "  2400   0.5  4528.8  6.337  6.453 0.98949\n",
      "  2410   0.5  4573.1  6.314  6.430 0.98945\n",
      "  2420   0.5  4335.2  6.381  6.497 0.98940\n",
      "  2430   0.5  4663.3  6.429  6.545 0.98936\n",
      "  2440   0.5  4427.2  6.322  6.438 0.98932\n",
      "  2450   0.5  4246.2  6.371  6.487 0.98927\n",
      "  2460   0.5  4234.4  6.355  6.472 0.98923\n",
      "  2470   0.5  4074.4  6.451  6.568 0.98919\n",
      "  2480   0.5  4064.0  6.370  6.487 0.98914\n",
      "  2490   0.5  4052.8  6.387  6.504 0.98910\n",
      "  2500   0.5  4054.1  6.326  6.443 0.98905\n",
      "  2510   0.5  4062.7  6.218  6.335 0.98901\n",
      "  2520   0.5  4210.0  6.349  6.467 0.98897\n",
      "  2530   0.5  4428.1  6.364  6.481 0.98892\n",
      "  2540   0.5  4435.2  6.381  6.499 0.98888\n",
      "  2550   0.5  4219.9  6.361  6.479 0.98884\n",
      "  2560   0.5  4432.9  6.285  6.403 0.98879\n",
      "  2570   0.5  4213.5  6.265  6.383 0.98875\n",
      "  2580   0.5  4222.7  6.421  6.539 0.98870\n",
      "  2590   0.5  4401.5  6.386  6.504 0.98866\n",
      "  2600   0.5  4285.8  6.354  6.473 0.98862\n",
      "  2610   0.5  4355.2  6.176  6.294 0.98857\n",
      "  2620   0.5  4107.8  6.364  6.483 0.98853\n",
      "  2630   0.5  4076.4  6.446  6.565 0.98849\n",
      "  2640   0.5  4019.3  6.213  6.332 0.98844\n",
      "  2650   0.5  4097.1  6.334  6.453 0.98840\n",
      "  2660   0.5  4038.8  6.327  6.446 0.98836\n",
      "  2670   0.5  4134.6  6.300  6.419 0.98831\n",
      "  2680   0.5  4345.6  6.324  6.443 0.98827\n",
      "  2690   0.5  4179.4  6.242  6.362 0.98822\n",
      "  2700   0.5  4188.8  6.349  6.469 0.98818\n",
      "  2710   0.5  4083.3  6.385  6.505 0.98814\n",
      "  2720   0.5  4197.1  6.313  6.433 0.98809\n",
      "  2730   0.5  4138.0  6.283  6.403 0.98805\n",
      "  2740   0.5  4660.0  6.179  6.299 0.98801\n",
      "  2750   0.5  4594.6  6.227  6.348 0.98796\n",
      "  2760   0.6  4698.1  6.397  6.517 0.98792\n",
      "  2770   0.6  4361.6  6.325  6.446 0.98788\n",
      "  2780   0.6  4096.0  6.179  6.299 0.98783\n",
      "  2790   0.6  4165.3  6.313  6.433 0.98779\n",
      "  2800   0.6  4070.2  6.276  6.397 0.98774\n",
      "  2810   0.6  4136.9  6.299  6.421 0.98770\n",
      "  2820   0.6  4204.2  6.182  6.303 0.98766\n",
      "  2830   0.6  4545.7  6.392  6.513 0.98761\n",
      "  2840   0.6  4583.8  6.338  6.460 0.98757\n",
      "  2850   0.6  4595.6  6.190  6.312 0.98753\n",
      "  2860   0.6  4646.3  6.176  6.298 0.98748\n",
      "  2870   0.6  4309.1  6.227  6.349 0.98744\n",
      "  2880   0.6  4301.8  6.285  6.407 0.98740\n",
      "  2890   0.6  4485.1  6.166  6.288 0.98735\n",
      "  2900   0.6  4609.5  6.255  6.377 0.98731\n",
      "  2910   0.6  4628.2  6.143  6.265 0.98726\n",
      "  2920   0.6  4193.0  6.139  6.262 0.98722\n",
      "  2930   0.6  4209.8  6.379  6.502 0.98718\n",
      "  2940   0.6  4050.3  6.211  6.334 0.98713\n",
      "  2950   0.6  4159.5  6.298  6.421 0.98709\n",
      "  2960   0.6  4600.0  6.265  6.388 0.98705\n",
      "  2970   0.6  4299.8  6.422  6.546 0.98700\n",
      "  2980   0.6  4057.8  6.361  6.485 0.98696\n",
      "  2990   0.6  4166.6  6.187  6.311 0.98692\n",
      "  3000   0.6  4152.6  6.226  6.350 0.98687\n",
      "  3010   0.6  4121.1  6.172  6.297 0.98683\n",
      "  3020   0.6  4181.0  6.315  6.439 0.98678\n",
      "  3030   0.6  4086.7  6.194  6.318 0.98674\n",
      "  3040   0.6  4209.1  6.193  6.318 0.98670\n",
      "  3050   0.6  4139.0  6.323  6.448 0.98665\n",
      "  3060   0.6  4226.9  6.339  6.464 0.98661\n",
      "  3070   0.6  4469.4  6.338  6.463 0.98657\n",
      "  3080   0.6  4273.9  6.214  6.340 0.98652\n",
      "  3090   0.6  4161.6  6.232  6.358 0.98648\n",
      "  3100   0.6  2981.9  6.234  6.360 0.98644\n",
      "  3110   0.6  4550.6  6.194  6.320 0.98639\n",
      "  3120   0.6  4552.8  6.231  6.357 0.98635\n",
      "  3130   0.6  4336.0  6.172  6.298 0.98630\n",
      "  3140   0.6  4129.3  6.336  6.462 0.98626\n",
      "  3150   0.6  4127.9  6.243  6.369 0.98622\n",
      "  3160   0.6  4560.8  6.322  6.448 0.98617\n",
      "  3170   0.6  4257.3  6.278  6.405 0.98613\n",
      "  3180   0.6  4464.3  6.269  6.395 0.98609\n",
      "  3190   0.6  4116.6  6.258  6.385 0.98604\n",
      "  3200   0.6  4072.1  6.253  6.380 0.98600\n",
      "  3210   0.6  4075.6  6.309  6.436 0.98596\n",
      "  3220   0.6  4073.8  6.160  6.287 0.98591\n",
      "  3230   0.6  4090.5  6.240  6.367 0.98587\n",
      "  3240   0.6  4142.7  6.112  6.239 0.98582\n",
      "  3250   0.6  4074.9  6.171  6.299 0.98578\n",
      "^C\n",
      "Keyboard interrupt\n"
     ]
    }
   ],
   "source": [
    "!./alexnet.py --data_dir /datasets/imagenet_TFrecords 2>/tmp/errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "Script arguments:\n",
      "  --predict False\n",
      "  --data_dir /datasets/imagenet_TFrecords\n",
      "  --precision fp16\n",
      "  --display_every 10\n",
      "  --num_iter 90\n",
      "  --iter_unit epoch\n",
      "  --batch_size 128\n",
      "Training\n",
      "  Step Epoch Img/sec   Loss  LR\n",
      "     1   0.0     9.5  7.037  8.149 1.00000\n",
      "    10   0.0    69.2  7.241  8.355 0.99998\n",
      "    20   0.0   460.8  7.128  8.244 0.99996\n",
      "    30   0.0   461.4  7.027  8.142 0.99994\n",
      "    40   0.0   461.4  6.953  8.062 0.99991\n",
      "    50   0.0   465.1  6.984  8.082 0.99989\n",
      "    60   0.0   465.0  6.961  8.044 0.99987\n",
      "    70   0.0   465.4  6.946  8.013 0.99985\n",
      "    80   0.0   464.5  6.922  7.971 0.99982\n",
      "    90   0.0   462.1  6.885  7.918 0.99980\n",
      "   100   0.0   463.7  6.907  7.924 0.99978\n",
      "   110   0.0   458.5  6.910  7.909 0.99976\n",
      "   120   0.0   463.2  6.857  7.839 0.99974\n",
      "   130   0.0   462.3  6.804  7.768 0.99971\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!./inception_v3.py --data_dir /datasets/imagenet_TFrecords 2>/tmp/errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "Script arguments:\n",
      "  --precision fp16\n",
      "  --display_every 10\n",
      "  --batch_size 256\n",
      "  --layers 50\n",
      "  --num_iter 90\n",
      "  --iter_unit epoch\n",
      "  --predict False\n",
      "Training\n",
      "  Step Epoch Img/sec   Loss  LR\n",
      "     1   1.0    24.5  7.660  8.631 2.00000\n",
      "    10  10.0   269.3  4.229  5.201 1.62000\n",
      "    20  20.0   867.2  0.059  1.036 1.24469\n",
      "    30  30.0   866.0  0.076  1.057 0.91877\n",
      "    40  40.0   863.5  0.075  1.058 0.64222\n",
      "    50  50.0   863.8  0.079  1.064 0.41506\n",
      "    60  60.0   862.5  0.186  1.172 0.23728\n",
      "    70  70.0   861.2  0.048  1.036 0.10889\n",
      "    80  80.0   864.8  0.001  0.990 0.02988\n",
      "    90  90.0   650.6  0.001  0.989 0.00025\n"
     ]
    }
   ],
   "source": [
    "!./resnet.py --layers=50 2>/tmp/errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "Script arguments:\n",
      "  --num_iter 90\n",
      "  --layers 50\n",
      "  --display_every 10\n",
      "  --iter_unit epoch\n",
      "  --data_dir /datasets/imagenet_TFrecords\n",
      "  --predict False\n",
      "  --batch_size 256\n",
      "  --precision fp16\n",
      "Training\n",
      "  Step Epoch Img/sec   Loss  LR\n",
      "     1   0.0    25.0  7.601  8.572 2.00000\n",
      "    10   0.0   226.7  7.568  8.540 1.99992\n",
      "    20   0.0   765.2  7.120  8.095 1.99983\n",
      "    30   0.0   861.9  7.060  8.039 1.99974\n",
      "    40   0.0   862.1  7.085  8.062 1.99965\n",
      "    50   0.0   859.9  7.073  8.047 1.99956\n",
      "    60   0.0   856.4  6.945  7.913 1.99948\n",
      "    70   0.0   863.3  6.982  7.941 1.99939\n",
      "    80   0.0   861.3  6.916  7.862 1.99930\n",
      "    90   0.0   866.3  6.854  7.784 1.99921\n",
      "   100   0.0   865.5  6.889  7.802 1.99912\n",
      "   110   0.0   860.1  6.924  7.824 1.99903\n",
      "   120   0.0   863.2  6.818  7.702 1.99894\n",
      "   130   0.0   862.1  6.935  7.801 1.99885\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!./resnet.py --layers=50 --data_dir=/datasets/imagenet_TFrecords 2>/tmp/errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "Script arguments:\n",
      "  --predict False\n",
      "  --layers 50\n",
      "  --batch_size 256\n",
      "  --precision fp32\n",
      "  --display_every 10\n",
      "  --num_iter 90\n",
      "  --iter_unit epoch\n",
      "  --data_dir /datasets/imagenet_TFrecords\n",
      "Training\n",
      "  Step Epoch Img/sec   Loss  LR\n"
     ]
    }
   ],
   "source": [
    "!./resnet.py --layers=50 --batch_size=256 --data_dir=/datasets/imagenet_TFrecords --precision=fp32 2>/tmp/errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "Script arguments:\n",
      "  --precision fp32\n",
      "  --display_every 10\n",
      "  --predict False\n",
      "  --layers 50\n",
      "  --num_iter 90\n",
      "  --batch_size 128\n",
      "  --iter_unit epoch\n",
      "  --data_dir /datasets/imagenet_TFrecords\n",
      "Training\n",
      "  Step Epoch Img/sec   Loss  LR\n",
      "     1   0.0    16.3  7.571  8.543 2.00000\n",
      "    10   0.0   121.3  8.120  9.092 1.99996\n",
      "    20   0.0   363.9  7.674  8.650 1.99992\n",
      "    30   0.0   392.8  7.400  8.380 1.99987\n",
      "    40   0.0   392.8  7.103  8.085 1.99983\n",
      "    50   0.0   391.5  7.004  7.984 1.99978\n",
      "    60   0.0   392.0  6.990  7.964 1.99974\n",
      "    70   0.0   391.1  6.948  7.909 1.99969\n",
      "    80   0.0   392.9  6.971  7.917 1.99965\n",
      "    90   0.0   389.5  6.933  7.863 1.99960\n",
      "   100   0.0   392.7  6.961  7.872 1.99956\n",
      "   110   0.0   392.2  7.180  8.071 1.99952\n",
      "   120   0.0   394.7  6.979  7.855 1.99947\n",
      "   130   0.0   392.9  6.905  7.762 1.99943\n",
      "   140   0.0   393.0  6.976  7.810 1.99938\n",
      "   150   0.0   393.0  6.888  7.699 1.99934\n",
      "   160   0.0   392.3  6.991  7.779 1.99929\n",
      "   170   0.0   393.0  6.888  7.654 1.99925\n",
      "   180   0.0   392.3  6.876  7.620 1.99921\n",
      "   190   0.0   392.0  6.815  7.538 1.99916\n",
      "   200   0.0   393.3  6.800  7.503 1.99912\n",
      "   210   0.0   391.3  7.000  7.685 1.99907\n",
      "   220   0.0   392.5  6.816  7.483 1.99903\n",
      "   230   0.0   392.8  6.804  7.453 1.99898\n",
      "   240   0.0   393.4  6.801  7.432 1.99894\n",
      "   250   0.0   392.3  6.840  7.453 1.99889\n",
      "   260   0.0   392.0  6.777  7.371 1.99885\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!./resnet.py --layers=50 --batch_size=128 --data_dir=/datasets/imagenet_TFrecords --precision=fp32 2>/tmp/errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DALI with Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "Script arguments:\n",
      "  --num_iter 90\n",
      "  --display_every 10\n",
      "  --data_idx_dir /datasets/imagenet_idx\n",
      "  --iter_unit epoch\n",
      "  --use_dali GPU\n",
      "  --predict False\n",
      "  --layers 50\n",
      "  --batch_size 256\n",
      "  --data_dir /datasets/imagenet_TFrecords\n",
      "  --precision fp16\n",
      "Training\n",
      "  Step Epoch Img/sec   Loss  LR\n",
      "     1   0.0    22.4  7.700  8.671 2.00000\n",
      "    10   0.0   248.6  7.694  8.666 1.99992\n",
      "    20   0.0   810.5  7.415  8.390 1.99983\n",
      "    30   0.0   845.9  7.405  8.382 1.99974\n",
      "    40   0.0   843.7  7.085  8.065 1.99965\n",
      "    50   0.0   833.9  6.991  7.966 1.99956\n",
      "    60   0.0   842.5  6.949  7.915 1.99948\n",
      "    70   0.0   840.9  7.771  8.724 1.99939\n",
      "    80   0.0   842.5  6.929  7.873 1.99930\n",
      "    90   0.0   843.1  7.002  7.937 1.99921\n",
      "   100   0.0   839.9  6.883  7.808 1.99912\n",
      "   110   0.0   837.3  6.926  7.839 1.99903\n",
      "   120   0.0   846.5  6.859  7.754 1.99894\n",
      "   130   0.0   833.7  6.779  7.652 1.99885\n",
      "   140   0.0   843.2  6.834  7.684 1.99877\n",
      "   150   0.0   849.8  6.816  7.642 1.99868\n",
      "   160   0.0   837.8  6.782  7.586 1.99859\n",
      "   170   0.0   840.7  6.767  7.549 1.99850\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!./resnet.py --layers=50 --data_dir=/datasets/imagenet_TFrecords --precision=fp16 --data_idx_dir /datasets/imagenet_idx --use_dali GPU 2>/tmp/error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DALI with Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "Script arguments:\n",
      "  --num_iter 91\n",
      "  --data_dir /datasets/imagenet_TFrecords\n",
      "  --display_every 10\n",
      "  --predict False\n",
      "  --use_dali GPU\n",
      "  --batch_size 256\n",
      "  --iter_unit epoch\n",
      "  --data_idx_dir /datasets/imagenet_idx\n",
      "  --precision fp16\n",
      "Training\n",
      "  Step Epoch Img/sec   Loss  LR\n",
      "     1   0.0    61.6  6.912  9.986 1.00000\n",
      "    10   0.0   745.1  6.927  9.968 0.99996\n",
      "    20   0.0  5591.9  6.910  9.802 0.99992\n",
      "    30   0.0  5590.1  6.912  9.583 0.99987\n",
      "    40   0.0  5558.6  6.915  9.348 0.99983\n",
      "    50   0.0  5535.5  6.899  9.102 0.99978\n",
      "    60   0.0  5547.8  6.907  8.896 0.99974\n",
      "    70   0.0  5557.9  6.916  8.711 0.99970\n",
      "    80   0.0  5582.6  6.900  8.519 0.99965\n",
      "    90   0.0  5547.7  6.907  8.368 0.99961\n",
      "   100   0.0  5598.3  6.908  8.225 0.99957\n",
      "   110   0.0  5577.5  6.907  8.094 0.99952\n",
      "   120   0.0  5626.7  6.907  7.978 0.99948\n",
      "   130   0.0  5612.0  6.908  7.877 0.99943\n",
      "   140   0.0  5573.5  6.910  7.786 0.99939\n",
      "   150   0.0  5604.0  6.912  7.702 0.99935\n",
      "   160   0.0  5595.9  6.908  7.621 0.99930\n",
      "   170   0.0  5547.8  6.908  7.550 0.99926\n",
      "   180   0.0  5543.4  6.907  7.487 0.99921\n",
      "   190   0.0  5584.3  6.912  7.436 0.99917\n",
      "   200   0.0  5606.4  6.914  7.390 0.99913\n",
      "   210   0.0  5496.5  6.903  7.336 0.99908\n",
      "   220   0.0  5475.5  6.913  7.311 0.99904\n",
      "   230   0.0  5529.7  6.896  7.268 0.99899\n",
      "   240   0.0  5495.6  6.869  7.220 0.99895\n",
      "   250   0.0  5543.9  6.868  7.200 0.99891\n",
      "   260   0.1  5514.4  6.843  7.160 0.99886\n",
      "   270   0.1  5504.4  6.871  7.174 0.99882\n",
      "   280   0.1  5527.7  6.860  7.151 0.99878\n",
      "   290   0.1  5485.4  6.830  7.111 0.99873\n",
      "   300   0.1  5474.9  6.829  7.102 0.99869\n",
      "   310   0.1  5523.2  6.800  7.066 0.99864\n",
      "   320   0.1  5496.8  6.844  7.103 0.99860\n",
      "   330   0.1  5411.1  6.861  7.113 0.99856\n",
      "   340   0.1  5559.8  6.866  7.112 0.99851\n",
      "   350   0.1  5499.2  6.822  7.063 0.99847\n",
      "   360   0.1  5516.1  6.767  7.003 0.99842\n",
      "   370   0.1  5543.6  6.808  7.040 0.99838\n",
      "   380   0.1  5486.5  6.822  7.049 0.99834\n",
      "   390   0.1  5547.2  6.818  7.041 0.99829\n",
      "   400   0.1  5539.2  6.790  7.008 0.99825\n",
      "   410   0.1  5451.0  6.793  7.006 0.99820\n",
      "   420   0.1  5579.3  6.847  7.057 0.99816\n",
      "   430   0.1  5531.6  6.755  6.961 0.99812\n",
      "   440   0.1  5554.3  6.789  6.990 0.99807\n",
      "   450   0.1  5526.1  6.801  6.999 0.99803\n",
      "   460   0.1  5516.4  6.775  6.969 0.99799\n",
      "   470   0.1  5497.6  6.807  6.998 0.99794\n",
      "   480   0.1  5441.2  6.792  6.980 0.99790\n",
      "   490   0.1  5567.4  6.805  6.990 0.99785\n",
      "   500   0.1  5474.0  6.795  6.977 0.99781\n",
      "   510   0.1  5437.3  6.815  6.994 0.99777\n",
      "   520   0.1  5477.6  6.814  6.990 0.99772\n",
      "   530   0.1  5506.9  6.769  6.943 0.99768\n",
      "   540   0.1  5507.7  6.763  6.933 0.99763\n",
      "   550   0.1  5588.3  6.833  7.002 0.99759\n",
      "   560   0.1  5588.8  6.680  6.846 0.99755\n",
      "   570   0.1  5630.4  6.786  6.951 0.99750\n",
      "   580   0.1  5611.7  6.825  6.988 0.99746\n",
      "   590   0.1  5587.1  6.763  6.924 0.99741\n",
      "   600   0.1  5584.7  6.871  7.029 0.99737\n",
      "   610   0.1  5564.7  6.742  6.898 0.99733\n",
      "   620   0.1  5595.4  6.769  6.924 0.99728\n",
      "   630   0.1  5634.0  6.777  6.931 0.99724\n",
      "   640   0.1  5569.0  6.733  6.885 0.99720\n",
      "   650   0.1  5571.0  6.750  6.901 0.99715\n",
      "   660   0.1  5501.6  6.766  6.915 0.99711\n",
      "   670   0.1  5557.0  6.794  6.942 0.99706\n",
      "   680   0.1  5557.9  6.715  6.861 0.99702\n",
      "   690   0.1  5513.1  6.835  6.980 0.99698\n",
      "   700   0.1  5637.5  6.736  6.879 0.99693\n",
      "   710   0.1  5561.6  6.719  6.862 0.99689\n",
      "   720   0.1  5586.4  6.757  6.899 0.99684\n",
      "   730   0.1  5605.7  6.728  6.868 0.99680\n",
      "   740   0.1  5585.3  6.761  6.901 0.99676\n",
      "   750   0.1  5585.8  6.723  6.861 0.99671\n",
      "   760   0.2  5601.0  6.685  6.822 0.99667\n",
      "   770   0.2  5549.1  6.669  6.805 0.99663\n",
      "^C\n",
      "Keyboard interrupt\n"
     ]
    }
   ],
   "source": [
    "!./alexnet.py --batch_size 256 --data_dir=/datasets/imagenet_TFrecords --precision=fp16 --data_idx_dir /datasets/imagenet_idx --use_dali GPU 2>/tmp/error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi GPU with Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "PY 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF 1.12.0\n",
      "Script arguments:\n",
      "  --display_every 10\n",
      "  --precision fp16\n",
      "  --num_iter 90\n",
      "  --use_dali GPU\n",
      "  --iter_unit epoch\n",
      "  --batch_size 256\n",
      "  --predict False\n",
      "  --data_idx_dir /datasets/imagenet_idx\n",
      "  --data_dir /datasets/imagenet_TFrecords\n",
      "  --layers 50\n",
      "Training\n",
      "Training\n",
      "Training\n",
      "Training\n",
      "Training\n",
      "Training\n",
      "Training\n",
      "Training\n",
      "  Step Epoch Img/sec   Loss  LR\n",
      "     1   0.0   145.2  7.633  8.605 2.00000\n",
      "    10   0.0  1524.2  7.346  8.317 1.99936\n",
      "    20   0.0  5221.9  7.185  8.156 1.99865\n",
      "    30   0.0  5315.8  7.027  7.991 1.99794\n",
      "    40   0.1  5346.1  7.150  8.101 1.99723\n",
      "    50   0.1  5596.1  6.758  7.694 1.99652\n",
      "    60   0.1  5587.2  6.672  7.590 1.99581\n",
      "    70   0.1  5541.0  6.598  7.496 1.99510\n",
      "    80   0.1  5630.0  6.381  7.259 1.99439\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!mpiexec --allow-run-as-root --bind-to socket -np 8 /workspace/nvidia-examples/cnn/resnet.py --layers=50 --data_dir=/datasets/imagenet_TFrecords --precision=fp16 --data_idx_dir /datasets/imagenet_idx --use_dali GPU 2>/tmp/error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
